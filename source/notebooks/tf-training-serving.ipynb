{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and serving Tensorflow models with Kubernetes Jobs and Seldon\n",
    "\n",
    "In this notebook we will use OpenShift client tools (`oc`) to build, train and deploy a Tensorflow model.\n",
    "\n",
    "First, we need to install the `oc` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -O https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.1/linux/oc.tar.gz\n",
    "tar xzf oc.tar.gz\n",
    "cp oc /opt/app-root/bin/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to login to OpenShift server and switch project to the one where this Jupyter server is running. We rely on two preconfigured environment variable - `$TOKEN` and `$NAMESPACE` here. There are 2 reasons for this - 1. to make the notebook reproducible without users having to manually change it and 2. to avoid displaying the secret (`$TOKEN`) in the Jupyter UI.\n",
    "\n",
    "_If this step fails you might need to go to `Control Panel > Stop My Server` and provide those environment variables in Spawner UI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc login --server https://openshift.default.svc.cluster.local --insecure-skip-tls-verify --token=$TOKEN\n",
    "oc project ${NAMESPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply resources available in https://gitlab.com/opendatahub/data-engineering-and-machine-learning-workshop repository. These contain necessary `BuildConfigs` and `Templates` to build and deploy the training `Job` and serving `SeldonDeployment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc apply -f ../tf-random-forest/openshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to successfully run the training job we need to wait for the container image build to finish. You can watch the logs output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc logs -f buildconfig.build.openshift.io/forest-mnist-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the parameters we can configure for the training job. Some of them come with default value, but some of them need to be configured by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc process forest-mnist-train --parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the predefined environment variables here again. The `MODEL_VERSION` parameter allows you to version your models - the value will be used for generation of the exported model file name so you will be able to switch between trained models in serving part.\n",
    "\n",
    "You can also experiment with `NUM_STEPS` to see if and how it influences the model accuracy. Do not forget to change `MODEL_VERSION` for each training though otherwise the following command will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc process forest-mnist-train \\\n",
    "-p S3_ENDPOINT_URL=${S3_ENDPOINT_URL} \\\n",
    "-p AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\\n",
    "-p AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\\n",
    "-p MODEL_VERSION=\"1\" | oc apply -f -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can watch the training output by running the cell below.\n",
    "\n",
    "Do not forget to change the name of job based on the output of the command above!\n",
    "\n",
    "You can find the `Test Accuracy` value close to the end of the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc logs -f job.batch/forest-mnist-train-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training job outputs a compressed model into S3 object storage (using the endpoint and credentials from the environment variables). It also creates a bucket if it does not exists.\n",
    "\n",
    "Let's take a look at what buckets exists in the object storage and see the trained model stored in the bucket.\n",
    "\n",
    "If you changed the bucket name for the training job, make sure you use the same value here in `Bucket=` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "conn = boto3.client(service_name='s3', \n",
    "                    endpoint_url=os.environ['S3_ENDPOINT_URL'])\n",
    "\n",
    "pprint(conn.list_buckets()['Buckets'])\n",
    "objects = conn.list_objects(Bucket=\"RHTE\")\n",
    "\n",
    "pprint(objects)\n",
    "print(\"Stored models: \", \", \".join([x['Key'] for x in objects['Contents']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is trained exported and stored in object storage we can serve it through Seldon. Let's take a look at the parameters for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc process forest-mnist-serve --parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see they are very similar to the training job parameters, which means we will need to provide the S3 storage credentials again and make sure `MODEL_NAME` and `MODEL_VERSION` match so that we deploy correct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc process forest-mnist-serve \\\n",
    "-p S3_ENDPOINT_URL=${S3_ENDPOINT_URL} \\\n",
    "-p AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\\n",
    "-p AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\\n",
    "-p MODEL_VERSION=\"1\" | oc apply -f -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc get pods -o name | grep forest-mnist-predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!oc logs -c forest-experiment pod/forest-mnist-predictor-28e5946-79c4996dd8-fp9z8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the serving container started successfully we can load some test data (using TF examples library) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `oc` command again to get the URL of the model prediction endpoint and store it as Python and Shell variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route=!oc get route forest-mnist -o \"jsonpath={.spec.host}\"\n",
    "route=route[0]\n",
    "%env SELDON_ROUTE=$route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can select our test sample. You can change the value of variable `y` to get different image from the test dataset. You will see the actual label which should later match the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=666\n",
    "x=[mnist.test.images[y].tolist()]\n",
    "print(\"Label: \", mnist.test.labels[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways how to query the model for predictions. Let's take a look at two of them - using a command line tool `curl` and a Python package `requests`.\n",
    "\n",
    "We export the variable `x` from the cell above as a shell environment variable and use it as a part of the payload to `/api/v0.1/predictions` edpoint.\n",
    "\n",
    "You will get a JSON back which contains probabilities for all the classes. Highest probability represents the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$x\"\n",
    "\n",
    "curl -k -X POST -H 'Content-Type: application/json' \\\n",
    "    -d \"{'data': {'ndarray': $1}}\" \\\n",
    "https://${SELDON_ROUTE}/api/v0.1/predictions 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bit easier to work with the JSON objects in Python, so we can actually print the guessed label with it's probability. \n",
    "\n",
    "Does it match the `Label` printed above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_label(predictions, names):\n",
    "    result = max(predictions)\n",
    "    return names[predictions.index(result)].split(\":\")[1], result\n",
    "    \n",
    "\n",
    "response = requests.post(\"https://%s/api/v0.1/predictions\" % route, json={'data': {'ndarray': x}}, verify=False).json()\n",
    "print(\"Predicted number is %s (%f) \" % (get_label(response['data']['ndarray'][0], response['data']['names'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with GPUs\n",
    "\n",
    "You will now attempt to train the same model on GPU using `tensorflow-gpu` package.\n",
    "\n",
    "First, we need to change the training script dependency. That can be done by changing `requirements.txt` for the training script. The command below will do that for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/tensorflow.*/tensorflow-gpu==1.13.*/' ../tf-random-forest/train/requirements.txt\n",
    "!cat ../tf-random-forest/train/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you did a local (i.e local to a container where Jupyter is running) change to the code of Python code for training, it is necessary to rebuild the training container image. It is also necessary to do it from the local directory (notice `--from-dir` parameter) instead of pulling the code from Git repositoy during the build.\n",
    "\n",
    "The following command will start a build and use local changes as a source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc start-build -F forest-mnist-train-gpu --from-dir=../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now start the training job. You can see messages like\n",
    "\n",
    "```\n",
    "2019-09-06 18:21:09.159963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\n",
    "```\n",
    "\n",
    "which means the job was actually scheduled on a GPU node and the Tensorflow will use the GPU to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc process forest-mnist-train-gpu \\\n",
    "-p S3_ENDPOINT_URL=${S3_ENDPOINT_URL} \\\n",
    "-p AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\\n",
    "-p AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\\n",
    "-p MODEL_VERSION=\"g1\" | oc apply -f -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!oc logs -f job.batch/forest-mnist-train-gpu-g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successful training you can deploy the newly built model same way we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "oc process forest-mnist-serve \\\n",
    "-p S3_ENDPOINT_URL=${S3_ENDPOINT_URL} \\\n",
    "-p AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\\n",
    "-p AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\\n",
    "-p MODEL_VERSION=\"g1\" | oc apply -f -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc get pods -o name | grep forest-mnist-predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc logs -f -c forest-experiment pod/forest-mnist-predictor-28e5946-74cc875f94-cnfm8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the Seldon deployment is running you can scroll up in the notebook and use the same code as before to call the prediction endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
